#![allow(dead_code)]
// TODO: once the lexer is in use, allow the dead_code warning again.

use std::{error::Error, fmt::Display, ops::Range};

use logos::Logos;

#[cfg(test)]
mod input_file_tests;
mod lower;
#[cfg(test)]
mod tests;

type Span = Range<usize>;

#[derive(Debug, PartialEq, Eq, Clone)]
pub(crate) struct Unrecognised<'a> {
    content: &'a str,
    span: Span,
}

impl Display for Unrecognised<'_> {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "'{}' is not part of the TX-2 assembler's character set",
            self.content
        )
    }
}

impl Error for Unrecognised<'_> {}

fn glyph_name(span: Span, prefix_len: usize) -> Span {
    (span.start + 1 + prefix_len)..(span.end - 1)
}

fn normal_glyph_name(lex: &mut logos::Lexer<Token>) -> Span {
    dbg!(lex.slice());
    glyph_name(lex.span(), 0)
}

fn sub_glyph_name(lex: &mut logos::Lexer<Token>) -> Span {
    dbg!(lex.slice());
    glyph_name(lex.span(), 4)
}

fn super_glyph_name(lex: &mut logos::Lexer<Token>) -> Span {
    dbg!(lex.slice());
    glyph_name(lex.span(), 6)
}

#[test]
fn test_glyph_name() {
    assert_eq!(glyph_name(0..6, 0), 1..5);
    assert_eq!(glyph_name(0..10, 4), 5..9);
}

/// The parser consumes these tokens.
#[derive(Debug, PartialEq, Eq, Logos, Clone)]
pub(crate) enum Token {
    LeftBrace,
    RightBrace,
    Newline,

    // Needs to be higher priority than AtGlyph*.
    #[regex("@arr@|->", priority = 20)]
    Arrow,

    // Needs to be higher priority than AtGlyph*.
    #[regex("@hand@|☛", priority = 20)]
    Hand,

    #[token("=")]
    Equals,

    #[token("|")]
    Pipe,

    // Needs to be higher priority than NormalSymexSyllable.
    #[regex("[0-9]+", priority = 20)]
    NormalDigits,

    // Needs to be higher priority than SubscriptSymexSyllable (when that's introduced).
    #[regex("([₀₁₂₃₄₅₆₇₈₉]|(@sub_([0-9])@))+", priority = 20)]
    SubscriptDigits,

    // Needs to be higher priority than SuperscriptSymexSyllable (when that's introduced).
    #[regex("([\u{2070}\u{00B9}\u{00B2}\u{00B3}\u{2074}\u{2075}\u{2076}\u{2077}\u{2078}\u{2079}]|(@super_([0-9])@))+", priority = 20)]
    SuperscriptDigits,

    // TODO: missing from this are: overbar, square, circle.
    #[regex(
        "([0-9A-ZαβγΔελijknpqtwxyz.'_]|(@(alpha|beta|gamma|delta|eps|lambda)@))+",
        priority = 15
    )]
    NormalSymexSyllable,

    #[regex("@super_[^@]*@", super_glyph_name, priority = 10)]
    AtGlyphSuper(Span),

    #[regex("@sub_[^@]*@", sub_glyph_name, priority = 10)]
    AtGlyphSub(Span),

    #[regex("@[^@]*@", normal_glyph_name, priority = 5)]
    AtGlyphNormal(Span),

    #[token(",")]
    Comma,
}

/// This is the primary lexer (and the only one accessible outside
/// this module).  It delegates the task of keeping track of whether
/// we're in an RC-block to a stateful "lower" lexer.  The "lower"
/// lexer's output is an enum, one of whose variants represents a
/// sequence of characters which we know don't contain an RC-block or
/// a comment.  These sequences are scanned by the "upper" lexer
/// (which is generated by Logos).
#[derive(Debug, Clone)]
pub(crate) struct Lexer<'a> {
    lower: lower::LowerLexer<'a>,
    upper: Option<logos::Lexer<'a, Token>>,
}

impl<'a> Lexer<'a> {
    pub(crate) fn new(input: &'a str) -> Lexer<'a> {
        Lexer {
            lower: lower::LowerLexer::new(input),
            upper: None,
        }
    }

    fn span(&self) -> Range<usize> {
        match self.upper.as_ref() {
            None => self.lower.span(),
            Some(upper) => {
                let offset = self.lower.span().start;
                let upper_span = upper.span();
                dbg!(offset);
                dbg!(&upper_span);
                dbg!((upper_span.start + offset)..(upper_span.end + offset))
            }
        }
    }

    fn next_upper(upper: &mut logos::Lexer<'a, Token>) -> Option<Result<Token, Unrecognised<'a>>> {
        match upper.next() {
            None => None,
            Some(Ok(token_from_upper)) => Some(Ok(token_from_upper)),
            Some(Err(_)) => Some(Err(Unrecognised {
                content: upper.slice(),
                span: upper.span(),
            })),
        }
    }

    fn spanned(&self) -> SpannedIter<'a> {
        SpannedIter {
            lexer: self.clone(),
        }
    }

    fn get_next(&mut self) -> Option<Result<Token, Unrecognised<'a>>> {
        use lower::Lexeme;
        if let Some(upper_lexer) = self.upper.as_mut() {
            match Lexer::next_upper(upper_lexer) {
                Some(r) => {
                    return Some(r);
                }
                None => {
                    // We have no more input from the upper lexer,
                    // fetch more from the lower one.
                }
            }
        }

        // Fetch more text from the lower lexer.
        self.upper = None;
        match self.lower.next() {
            Lexeme::EndOfInput => None,
            Lexeme::Tok(tok) => Some(Ok(tok)),
            // If the lower lexer actually returns Unrecognised, the
            // slice in `content` is likely very short (a single
            // character perhaps) and that is unlikely to be
            // tokenizable.  So the upper lexer will likely also
            // return an error for that text too.
            Lexeme::Text(text)
            | Lexeme::Err(Unrecognised {
                content: text,
                span: _,
            }) => {
                let lexer = logos::Lexer::new(text);
                self.upper = Some(lexer);
                Lexer::next_upper(
                    self.upper
                        .as_mut()
                        .expect("the option cannot be empty, we just filled it"),
                )
            }
        }
    }
}

impl<'a> Iterator for Lexer<'a> {
    type Item = Result<Token, Unrecognised<'a>>;

    fn next(&mut self) -> Option<Result<Token, Unrecognised<'a>>> {
        self.get_next()
    }
}

#[derive(Debug, Clone)]
struct SpannedIter<'a> {
    lexer: Lexer<'a>,
}

impl<'a> Iterator for SpannedIter<'a> {
    type Item = Result<(Token, Span), Unrecognised<'a>>;

    fn next(&mut self) -> Option<Self::Item> {
        match self.lexer.next() {
            Some(Ok(tok)) => Some(Ok((tok, self.lexer.span()))),
            Some(Err(e)) => Some(Err(e)),
            None => None,
        }
    }
}
